{
 "metadata": {
  "name": "",
  "signature": "sha256:92075c16f3d3199dde47b3d81d5ab30c9c28dda0ac457993af4e19c952948d49"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import math\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv(\"train.csv\")\n",
      "train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(878049, 9)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Dates</th>\n",
        "      <th>Category</th>\n",
        "      <th>Descript</th>\n",
        "      <th>DayOfWeek</th>\n",
        "      <th>PdDistrict</th>\n",
        "      <th>Resolution</th>\n",
        "      <th>Address</th>\n",
        "      <th>X</th>\n",
        "      <th>Y</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 2015-05-13 23:53:00</td>\n",
        "      <td>       WARRANTS</td>\n",
        "      <td>               WARRANT ARREST</td>\n",
        "      <td> Wednesday</td>\n",
        "      <td> NORTHERN</td>\n",
        "      <td> ARREST, BOOKED</td>\n",
        "      <td>        OAK ST / LAGUNA ST</td>\n",
        "      <td>-122.425892</td>\n",
        "      <td> 37.774599</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2015-05-13 23:53:00</td>\n",
        "      <td> OTHER OFFENSES</td>\n",
        "      <td>     TRAFFIC VIOLATION ARREST</td>\n",
        "      <td> Wednesday</td>\n",
        "      <td> NORTHERN</td>\n",
        "      <td> ARREST, BOOKED</td>\n",
        "      <td>        OAK ST / LAGUNA ST</td>\n",
        "      <td>-122.425892</td>\n",
        "      <td> 37.774599</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 2015-05-13 23:33:00</td>\n",
        "      <td> OTHER OFFENSES</td>\n",
        "      <td>     TRAFFIC VIOLATION ARREST</td>\n",
        "      <td> Wednesday</td>\n",
        "      <td> NORTHERN</td>\n",
        "      <td> ARREST, BOOKED</td>\n",
        "      <td> VANNESS AV / GREENWICH ST</td>\n",
        "      <td>-122.424363</td>\n",
        "      <td> 37.800414</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 2015-05-13 23:30:00</td>\n",
        "      <td>  LARCENY/THEFT</td>\n",
        "      <td> GRAND THEFT FROM LOCKED AUTO</td>\n",
        "      <td> Wednesday</td>\n",
        "      <td> NORTHERN</td>\n",
        "      <td>           NONE</td>\n",
        "      <td>  1500 Block of LOMBARD ST</td>\n",
        "      <td>-122.426995</td>\n",
        "      <td> 37.800873</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 2015-05-13 23:30:00</td>\n",
        "      <td>  LARCENY/THEFT</td>\n",
        "      <td> GRAND THEFT FROM LOCKED AUTO</td>\n",
        "      <td> Wednesday</td>\n",
        "      <td>     PARK</td>\n",
        "      <td>           NONE</td>\n",
        "      <td> 100 Block of BRODERICK ST</td>\n",
        "      <td>-122.438738</td>\n",
        "      <td> 37.771541</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "                 Dates        Category                      Descript  \\\n",
        "0  2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
        "1  2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
        "2  2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
        "3  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
        "4  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
        "\n",
        "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
        "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
        "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
        "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
        "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
        "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
        "\n",
        "            X          Y  \n",
        "0 -122.425892  37.774599  \n",
        "1 -122.425892  37.774599  \n",
        "2 -122.424363  37.800414  \n",
        "3 -122.426995  37.800873  \n",
        "4 -122.438738  37.771541  "
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "strain = train[0:10]\n",
      "\n",
      "sterms = strain[[\"Address\",\"PdDistrict\",\"DayOfWeek\"]].apply(lambda x : \" \".join(set(\" \".join(x).split())), axis=1)\n",
      "print sterms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0              NORTHERN OAK Wednesday / ST LAGUNA\n",
        "1              NORTHERN OAK Wednesday / ST LAGUNA\n",
        "2    GREENWICH NORTHERN Wednesday / ST AV VANNESS\n",
        "3     LOMBARD NORTHERN of Wednesday ST 1500 Block\n",
        "4        BRODERICK of PARK Wednesday ST 100 Block\n",
        "5         TEDDY INGLESIDE of Wednesday 0 AV Block\n",
        "6            INGLESIDE Wednesday / AVALON PERU AV\n",
        "7      Wednesday / ST KIRKWOOD AV BAYVIEW DONAHUE\n",
        "8         600 of Wednesday RICHMOND 47TH AV Block\n",
        "9    CENTRAL LEAVENWORTH Wednesday / ST JEFFERSON\n",
        "dtype: object\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "terms = train[[\"Address\",\"PdDistrict\",\"DayOfWeek\"]].apply(lambda x : \" \".join(set(\" \".join(x).split())), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(terms)\n",
      "print terms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.series.Series'>\n",
        "0               NORTHERN OAK Wednesday / ST LAGUNA\n",
        "1               NORTHERN OAK Wednesday / ST LAGUNA\n",
        "2     GREENWICH NORTHERN Wednesday / ST AV VANNESS\n",
        "3      LOMBARD NORTHERN of Wednesday ST 1500 Block\n",
        "4         BRODERICK of PARK Wednesday ST 100 Block\n",
        "5          TEDDY INGLESIDE of Wednesday 0 AV Block\n",
        "6             INGLESIDE Wednesday / AVALON PERU AV\n",
        "7       Wednesday / ST KIRKWOOD AV BAYVIEW DONAHUE\n",
        "8          600 of Wednesday RICHMOND 47TH AV Block\n",
        "9     CENTRAL LEAVENWORTH Wednesday / ST JEFFERSON\n",
        "10    CENTRAL LEAVENWORTH Wednesday / ST JEFFERSON\n",
        "11         ESCOLTA of Wednesday 0 TARAVAL Block WY\n",
        "12            JONES Wednesday TENDERLOIN ST TURK /\n",
        "13       FILLMORE NORTHERN BL Wednesday / ST GEARY\n",
        "14      200 of Wednesday Block AV BAYVIEW WILLIAMS\n",
        "...\n",
        "878034        Monday 22ND of RICHMOND AV Block 1000\n",
        "878035     1300 Monday NORTHERN of ST WEBSTER Block\n",
        "878036     1300 Monday NORTHERN of ST WEBSTER Block\n",
        "878037     1300 Monday NORTHERN of ST WEBSTER Block\n",
        "878038          TAYLOR Monday TENDERLOIN ST / GEARY\n",
        "878039         NORTHERN Monday / ST CALIFORNIA POLK\n",
        "878040       Monday of MISSION ST FOLSOM 2800 Block\n",
        "878041         Monday / 14TH RICHMOND AV ST CLEMENT\n",
        "878042      Monday of SHAFTER 1500 AV BAYVIEW Block\n",
        "878043      Monday of SHAFTER 1500 AV BAYVIEW Block\n",
        "878044    CAPITOL Monday / ST TARAVAL FARALLONES AV\n",
        "878045        600 Monday EDNA of ST INGLESIDE Block\n",
        "878046              Monday 5TH SOUTHERN / ST FOLSOM\n",
        "878047            Monday SOUTHERN / 2ND ST TOWNSEND\n",
        "878048      Monday 1800 of AV BAYVIEW NEWCOMB Block\n",
        "Length: 878049, dtype: object\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_list = pd.DataFrame(terms.str.split().tolist()).stack().value_counts().keys().values\n",
      "print type(term_list)\n",
      "print term_list\n",
      "\n",
      "stopwords = [\"Block\"]\n",
      "for t in term_list:\n",
      "    if len(t) < 3:\n",
      "        stopwords.append(t)\n",
      "        \n",
      "print stopwords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'numpy.ndarray'>\n",
        "['ST' 'Block' 'of' ..., 'DIEGO' 'MILEY' 'BOOM']\n",
        "['Block', 'ST', 'of', '/', 'AV', '0', 'BL', 'DR', 'WY', 'RD', 'CT', 'HY', 'PZ', 'LN', 'PL', 'TR', 'LA', 'AL', 'JR', 'CR', 'F', 'DE', 'MC', 'A', 'OF', 'MT', 'PT', 'V', 'GG', 'EL', 'LE', 'J', 'EX', 'P', 'FE', 'WK', 'SF', 'US', 'I', 'RW', 'B']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_labels = np.sort(train[\"Category\"].unique())\n",
      "print cat_labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['ARSON' 'ASSAULT' 'BAD CHECKS' 'BRIBERY' 'BURGLARY' 'DISORDERLY CONDUCT'\n",
        " 'DRIVING UNDER THE INFLUENCE' 'DRUG/NARCOTIC' 'DRUNKENNESS' 'EMBEZZLEMENT'\n",
        " 'EXTORTION' 'FAMILY OFFENSES' 'FORGERY/COUNTERFEITING' 'FRAUD' 'GAMBLING'\n",
        " 'KIDNAPPING' 'LARCENY/THEFT' 'LIQUOR LAWS' 'LOITERING' 'MISSING PERSON'\n",
        " 'NON-CRIMINAL' 'OTHER OFFENSES' 'PORNOGRAPHY/OBSCENE MAT' 'PROSTITUTION'\n",
        " 'RECOVERED VEHICLE' 'ROBBERY' 'RUNAWAY' 'SECONDARY CODES'\n",
        " 'SEX OFFENSES FORCIBLE' 'SEX OFFENSES NON FORCIBLE' 'STOLEN PROPERTY'\n",
        " 'SUICIDE' 'SUSPICIOUS OCC' 'TREA' 'TRESPASS' 'VANDALISM' 'VEHICLE THEFT'\n",
        " 'WARRANTS' 'WEAPON LAWS']\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(term_list)\n",
      "print len(cat_labels)\n",
      "\n",
      "print (cat_labels == \"EMBEZZLEMENT\").astype(int)\n",
      "term_list==\"NORTHERN\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2163\n",
        "39\n",
        "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
        " 0 0]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "array([False, False, False, ..., False, False, False], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inputs  = terms.values\n",
      "outputs = train[\"Category\"].values\n",
      "\n",
      "split = int(0.9 * inputs.shape[0])\n",
      "\n",
      "idx = np.arange(inputs.shape[0])\n",
      "np.random.shuffle(idx)\n",
      "\n",
      "idx_train = idx[0:split]\n",
      "idx_test  = idx[split:inputs.shape[0]]\n",
      "\n",
      "train_in_set = inputs[idx_train] \n",
      "train_out_set = outputs[idx_train] \n",
      "\n",
      "test_in_set  = inputs[idx_test]\n",
      "test_out_set  = outputs[idx_test]\n",
      "\n",
      "print train_in_set.shape\n",
      "print train_out_set.shape\n",
      "\n",
      "print test_in_set.shape\n",
      "print test_out_set.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(790244,)\n",
        "(790244,)\n",
        "(87805,)\n",
        "(87805,)\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_term_freq(term_list, cat_labels, train_in, train_out):\n",
      "    # note this.. the counts start at *1* giving uniform chance to all cats.. counts then offset this \n",
      "    term_cat_freq_count = np.ones((len(term_list), len(cat_labels)))\n",
      "    for i in xrange(len(train_in)):\n",
      "        cat_weight = (cat_labels == train_out[i]).astype(int)\n",
      "        terms = train_in[i].split()\n",
      "        for t in terms:\n",
      "            idx = term_list==t\n",
      "            term_cat_freq_count[idx,:] += cat_weight\n",
      "    return term_cat_freq_count\n",
      "        \n",
      "def train_term_tfdif(term_cat_freq_count):\n",
      "    sums = np.sum(term_cat_freq_count, axis=1)\n",
      "    # term_tfidf = (term_cat_freq_count.transpose() / sums).transpose() \n",
      "    term_tfidf = np.log(sums) - np.log(sums/term_cat_freq_count.transpose())\n",
      "\n",
      "    return term_tfidf.transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_cat_freq_count = train_term_freq(term_list, cat_labels, train_in_set, train_out_set)\n",
      "print term_cat_freq_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_tfidf = train_term_tfdif(term_cat_freq_count)\n",
      "print term_tfidf\n",
      "print term_tfidf.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  6.79458658  10.85661153   5.6094718  ...,  10.47990427  10.37990805\n",
        "    8.64276801]\n",
        " [  7.02642681  10.91965982   5.82894562 ...,  10.33608133  10.13400386\n",
        "    8.61377529]\n",
        " [  7.02642681  10.91965982   5.82894562 ...,  10.33608133  10.13400386\n",
        "    8.61377529]\n",
        " ..., \n",
        " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
        " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
        " [  0.           0.           0.         ...,   0.           0.           0.        ]]\n",
        "(2163, 39)\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_term_tfidf(stopwords, term_list, term_tfidf, data):\n",
      "    # basicly we combine the pdf for each term by assuming terms are mutex\n",
      "    pdf = np.zeros((data.shape[0],len(cat_labels)))/len(cat_labels)\n",
      "        \n",
      "    for i in xrange(len(data)):\n",
      "        terms = data[i].split()\n",
      "        for t in terms:\n",
      "            if (not t in stopwords):                    \n",
      "                idx = term_list==t\n",
      "                pdf[i,:] += term_tfidf[idx,:].reshape((term_tfidf.shape[1])) \n",
      "        \n",
      "    return pdf\n",
      "\n",
      "def run_term_freq(stopwords, term_list, term_cat_freq_count, data):\n",
      "    # basicly we combine the pdf for each term by assuming terms are mutex\n",
      "    pdf = np.ones((data.shape[0],len(cat_labels)))/len(cat_labels)\n",
      "        \n",
      "    for i in xrange(len(data)):\n",
      "        terms = data[i].split()\n",
      "        for t in terms:\n",
      "            if (not t in stopwords):                    \n",
      "                idx = term_list==t\n",
      "                freq = term_cat_freq_count[idx,:].reshape((term_cat_freq_count.shape[1]))         \n",
      "                sums = np.sum(freq)\n",
      "                pdf[i,:] *= freq / sums \n",
      "    return pdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def logloss(actual, result):\n",
      "    epsilon = 1e-15\n",
      "    pred = np.maximum(  epsilon, result)\n",
      "    pred = np.minimum(1-epsilon, result)\n",
      "    ll = -1.0 * np.mean(actual*np.log(result) + (1.0 - actual)*np.log(1.0 - result), axis=0)\n",
      "    return np.sum(ll)\n",
      "\n",
      "def accuracy(actual, result):\n",
      "    correct_prediction = np.argmax(result,axis=1) == np.argmax(actual,axis=1)\n",
      "    accuracy = float(np.sum(correct_prediction)) / float(correct_prediction.shape[0])\n",
      "\n",
      "    lloss = logloss(actual,result)\n",
      "\n",
      "    print \" correct:\", np.sum(correct_prediction), \"/\", correct_prediction.shape[0]\n",
      "    print \" accuracy:\", accuracy, \"log loss\", lloss"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_out = run_term_tfidf(stopwords, term_list, term_tfidf, test_in_set)\n",
      "print model_out.shape\n",
      "print model_out\n",
      "\n",
      "accuracy(test_out_set, model_out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(87805, 39)\n",
        "[[ 13.77468856  29.1112204    8.76155014 ...,  28.65154721  25.87054347\n",
        "   20.58860119]\n",
        " [ 15.76673229  32.59692887  11.67422765 ...,  30.11622496  30.07817929\n",
        "   23.32380678]\n",
        " [ 14.81417727  28.1245649   10.29444797 ...,  28.03360738  23.19125281\n",
        "   19.75412501]\n",
        " ..., \n",
        " [ 15.06225545  28.13599688   7.59287029 ...,  27.11049157  26.60917209\n",
        "   22.03987022]\n",
        " [ 15.17894562  35.11287791  11.92190439 ...,  34.40027644  31.66848439\n",
        "   24.44206926]\n",
        " [ 14.07802866  30.63018138   7.42177579 ...,  27.71811942  29.51854589\n",
        "   21.99227846]]\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "axis(=1) out of bounds",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-51-8f9b1ec79252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmodel_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_out_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-46-0b3a2d6c634f>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(actual, result)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcorrect_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/shade/.local/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: axis(=1) out of bounds"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_out2 =  run_term_freq([], term_list, term_tfidf, test_in_set)\n",
      "accuracy(test_out_set, model_out2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model_out[0]\n",
      "print model_out2[0]\n",
      "\n",
      "print \"stop word check\"\n",
      "print test_in_set[0]\n",
      "\n",
      "cut_in = np.array([\"of Tuesday SOUTHERN ST 4TH 100 Block\"])\n",
      "cut_in2 = np.array([\"Tuesday SOUTHERN 4TH 100\"])\n",
      "cut_out = test_out_set[0]\n",
      "\n",
      "cut_model_out  = run_term_freq([], term_list, term_tfidf, cut_in)\n",
      "cut_model_out2 = run_term_freq([], term_list, term_tfidf, cut_in2)\n",
      "\n",
      "print cut_model_out\n",
      "print cut_model_out2\n",
      "print (cut_model_out - cut_model_out2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "width = len(cat_labels)\n",
      "stuff = run_term_freq([], term_list, term_tfidf, np.array([\"/\"])).reshape(width)\n",
      "print stuff.shape\n",
      "\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(range(width), stuff)\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.setStopword(stopwords)\n",
      "\n",
      "with open(\"model_term_cat_freq_count.npz\", 'w') as outfile:\n",
      "    np.savez(outfile,\n",
      "            term_list=term_list,\n",
      "            cat_labels=cat_labels,\n",
      "            stopwords=stopwords,\n",
      "            term_cat_freq_count=term_cat_freq_count,\n",
      "            term_tfidf=term_tfidf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}