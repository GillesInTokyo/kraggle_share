{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In original dataset we have about 37 million training set rows, and 2 million testing set rows. That's too much to read in memory, we'll sample n rows from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load random sample from train data\n",
    "def load_sample(filename, sample_size, nrows=False):\n",
    "    \n",
    "    # if number of rows in file is unknown\n",
    "    if not nrows: \n",
    "        nrows = sum(1 for line in open(filename)) - 1 # number of records in file (excludes header)\n",
    "\n",
    "    skip = sorted(random.sample(xrange(1, nrows + 1), nrows-sample_size)) # the 0-indexed header will not be included in the skip list\n",
    "    df = pd.read_csv(filename, skiprows=skip)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load 10000 test rows\n",
    "test = load_sample(\"test.csv\", sample_size=10000, nrows=2528243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users in test set:  9932\n"
     ]
    }
   ],
   "source": [
    "test_ids = set(test.user_id.unique())\n",
    "print \"Number of unique users in test set: \", len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load train data into chunks and filter it by user ids\n",
    "iter_csv = pd.read_csv('train.csv', iterator=True, chunksize=10000)\n",
    "train = pd.concat([chunk[chunk['user_id'].isin(test_ids)] for chunk in iter_csv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load destinations data\n",
    "destinations = pd.read_csv('destinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save sample datasets\n",
    "train.to_csv(\"train_sample.csv\")\n",
    "test.to_csv(\"test_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first look at how much data there is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501201, 24)\n",
      "(10000, 22)\n",
      "(62106, 150)\n"
     ]
    }
   ],
   "source": [
    "print train.shape\n",
    "print test.shape\n",
    "print destinations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In original dataset we have about 37 million training set rows, and 2 million testing set rows, which will make this problem a bit challenging to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>...</th>\n",
       "      <th>srch_children_cnt</th>\n",
       "      <th>srch_rm_cnt</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_destination_type_id</th>\n",
       "      <th>is_booking</th>\n",
       "      <th>cnt</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>hotel_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>2013-04-17 21:00:35</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>462</td>\n",
       "      <td>3492</td>\n",
       "      <td>1608.2975</td>\n",
       "      <td>14117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11815</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1701</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>2013-04-17 21:05:54</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>462</td>\n",
       "      <td>3492</td>\n",
       "      <td>1608.9681</td>\n",
       "      <td>14117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11815</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1701</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>2013-04-17 21:12:59</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>462</td>\n",
       "      <td>3492</td>\n",
       "      <td>1608.4897</td>\n",
       "      <td>14117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11815</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1701</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>2013-04-17 21:16:48</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>462</td>\n",
       "      <td>3492</td>\n",
       "      <td>1608.2975</td>\n",
       "      <td>14117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11815</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1701</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>2013-04-17 21:20:08</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>462</td>\n",
       "      <td>3492</td>\n",
       "      <td>1607.9680</td>\n",
       "      <td>14117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11815</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1701</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_time  site_name  posa_continent  user_location_country  \\\n",
       "2725  2013-04-17 21:00:35          8               4                     77   \n",
       "2726  2013-04-17 21:05:54          8               4                     77   \n",
       "2727  2013-04-17 21:12:59          8               4                     77   \n",
       "2728  2013-04-17 21:16:48          8               4                     77   \n",
       "2729  2013-04-17 21:20:08          8               4                     77   \n",
       "\n",
       "      user_location_region  user_location_city  orig_destination_distance  \\\n",
       "2725                   462                3492                  1608.2975   \n",
       "2726                   462                3492                  1608.9681   \n",
       "2727                   462                3492                  1608.4897   \n",
       "2728                   462                3492                  1608.2975   \n",
       "2729                   462                3492                  1607.9680   \n",
       "\n",
       "      user_id  is_mobile  is_package      ...        srch_children_cnt  \\\n",
       "2725    14117          0           1      ...                        0   \n",
       "2726    14117          0           1      ...                        0   \n",
       "2727    14117          0           1      ...                        0   \n",
       "2728    14117          0           1      ...                        0   \n",
       "2729    14117          0           1      ...                        0   \n",
       "\n",
       "     srch_rm_cnt srch_destination_id  srch_destination_type_id  is_booking  \\\n",
       "2725           1               11815                         1           0   \n",
       "2726           1               11815                         1           0   \n",
       "2727           1               11815                         1           0   \n",
       "2728           1               11815                         1           0   \n",
       "2729           1               11815                         1           0   \n",
       "\n",
       "      cnt  hotel_continent  hotel_country  hotel_market  hotel_cluster  \n",
       "2725    1                3              5          1701             81  \n",
       "2726    1                3              5          1701             12  \n",
       "2727    1                3              5          1701             30  \n",
       "2728    2                3              5          1701             81  \n",
       "2729    1                3              5          1701             78  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things that immediately stick out:\n",
    "\n",
    "* date_time could be useful in our predictions, so we’ll need to convert it.\n",
    "* Most of the columns are integers or floats, so we can’t do a lot of feature engineering. For example, user_location_country isn’t the name of a country, it’s an integer. This makes it harder to create new features, because we don’t know exactly which each value means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>...</th>\n",
       "      <th>srch_ci</th>\n",
       "      <th>srch_co</th>\n",
       "      <th>srch_adults_cnt</th>\n",
       "      <th>srch_children_cnt</th>\n",
       "      <th>srch_rm_cnt</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_destination_type_id</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211</td>\n",
       "      <td>2015-03-19 13:53:11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>174</td>\n",
       "      <td>244</td>\n",
       "      <td>2032.0594</td>\n",
       "      <td>801</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12572</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>330</td>\n",
       "      <td>2015-04-13 13:39:47</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>363</td>\n",
       "      <td>25671</td>\n",
       "      <td>80.9348</td>\n",
       "      <td>1153</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-05-15</td>\n",
       "      <td>2015-05-16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8219</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>429</td>\n",
       "      <td>2015-06-13 14:48:09</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>195</td>\n",
       "      <td>991</td>\n",
       "      <td>43633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1417</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-03</td>\n",
       "      <td>2015-10-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>929</td>\n",
       "      <td>2015-11-04 14:31:23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>311</td>\n",
       "      <td>4979</td>\n",
       "      <td>77.9177</td>\n",
       "      <td>3033</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27819</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1025</td>\n",
       "      <td>2015-04-29 13:14:41</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>1210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3289</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-05-16</td>\n",
       "      <td>2015-05-18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8220</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id            date_time  site_name  posa_continent  \\\n",
       "0   211  2015-03-19 13:53:11          2               3   \n",
       "1   330  2015-04-13 13:39:47          2               3   \n",
       "2   429  2015-06-13 14:48:09         30               4   \n",
       "3   929  2015-11-04 14:31:23          2               3   \n",
       "4  1025  2015-04-29 13:14:41         24               2   \n",
       "\n",
       "   user_location_country  user_location_region  user_location_city  \\\n",
       "0                     66                   174                 244   \n",
       "1                     66                   363               25671   \n",
       "2                    195                   991               43633   \n",
       "3                     66                   311                4979   \n",
       "4                      3                    63                1210   \n",
       "\n",
       "   orig_destination_distance  user_id  is_mobile      ...          srch_ci  \\\n",
       "0                  2032.0594      801          0      ...       2015-03-31   \n",
       "1                    80.9348     1153          0      ...       2015-05-15   \n",
       "2                        NaN     1417          1      ...       2015-10-03   \n",
       "3                    77.9177     3033          0      ...       2015-11-13   \n",
       "4                        NaN     3289          0      ...       2015-05-16   \n",
       "\n",
       "      srch_co srch_adults_cnt srch_children_cnt  srch_rm_cnt  \\\n",
       "0  2015-04-01               1                 0            1   \n",
       "1  2015-05-16               2                 0            1   \n",
       "2  2015-10-04               2                 0            1   \n",
       "3  2015-11-16               2                 0            1   \n",
       "4  2015-05-18               2                 0            1   \n",
       "\n",
       "   srch_destination_id  srch_destination_type_id  hotel_continent  \\\n",
       "0                12572                         5                2   \n",
       "1                 8219                         1                2   \n",
       "2                41544                         1                0   \n",
       "3                27819                         6                2   \n",
       "4                 8220                         1                3   \n",
       "\n",
       "   hotel_country  hotel_market  \n",
       "0             50           680  \n",
       "1             50           688  \n",
       "2             34            97  \n",
       "3             50           690  \n",
       "4            182            46  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things we can take away from looking at test.csv:\n",
    "\n",
    "* It looks like all the dates in test.csv are later than the dates in train.csv, and the data page confirms this. The testing set contains dates from 2015, and the training set contains dates from 2013 and 2014.\n",
    "* It looks like the user ids in test.csv are a subset of the user ids in train.csv, given the overlapping integer ranges. We can confirm this later on.\n",
    "* The is_booking column always looks to be 1 in test.csv. The data page confirms this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>...</th>\n",
       "      <th>d140</th>\n",
       "      <th>d141</th>\n",
       "      <th>d142</th>\n",
       "      <th>d143</th>\n",
       "      <th>d144</th>\n",
       "      <th>d145</th>\n",
       "      <th>d146</th>\n",
       "      <th>d147</th>\n",
       "      <th>d148</th>\n",
       "      <th>d149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.082564</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.031597</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.183490</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.189562</td>\n",
       "      <td>-2.105819</td>\n",
       "      <td>-2.075407</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.118483</td>\n",
       "      <td>-2.140393</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.196379</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.192009</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.057548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.115485</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.161081</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.189562</td>\n",
       "      <td>-2.187783</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.171153</td>\n",
       "      <td>-2.152303</td>\n",
       "      <td>-2.056618</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.145911</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.187356</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.191779</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.185161</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.188037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_destination_id        d1        d2        d3        d4        d5  \\\n",
       "0                    0 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657   \n",
       "1                    1 -2.181690 -2.181690 -2.181690 -2.082564 -2.181690   \n",
       "2                    2 -2.183490 -2.224164 -2.224164 -2.189562 -2.105819   \n",
       "3                    3 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409   \n",
       "4                    4 -2.189562 -2.187783 -2.194008 -2.171153 -2.152303   \n",
       "\n",
       "         d6        d7        d8        d9    ...         d140      d141  \\\n",
       "0 -1.897627 -2.198657 -2.198657 -1.897627    ...    -2.198657 -2.198657   \n",
       "1 -2.165028 -2.181690 -2.181690 -2.031597    ...    -2.165028 -2.181690   \n",
       "2 -2.075407 -2.224164 -2.118483 -2.140393    ...    -2.224164 -2.224164   \n",
       "3 -2.115485 -2.177409 -2.177409 -2.177409    ...    -2.161081 -2.177409   \n",
       "4 -2.056618 -2.194008 -2.194008 -2.145911    ...    -2.187356 -2.194008   \n",
       "\n",
       "       d142      d143      d144      d145      d146      d147      d148  \\\n",
       "0 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657   \n",
       "1 -2.165028 -2.181690 -2.181690 -2.165028 -2.181690 -2.181690 -2.181690   \n",
       "2 -2.196379 -2.224164 -2.192009 -2.224164 -2.224164 -2.224164 -2.224164   \n",
       "3 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409   \n",
       "4 -2.191779 -2.194008 -2.194008 -2.185161 -2.194008 -2.194008 -2.194008   \n",
       "\n",
       "       d149  \n",
       "0 -2.198657  \n",
       "1 -2.181690  \n",
       "2 -2.057548  \n",
       "3 -2.177409  \n",
       "4 -2.188037  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figuring out what to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll be predicting which hotel_cluster a user will book after a given search. According to the description, there are 100 clusters in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91    14094\n",
      "64    10987\n",
      "48    10399\n",
      "41    10132\n",
      "5      8853\n",
      "82     8393\n",
      "Name: hotel_cluster, dtype: int64\n",
      "...\n",
      "35    2040\n",
      "24    1939\n",
      "27    1327\n",
      "88    1141\n",
      "74     565\n",
      "Name: hotel_cluster, dtype: int64\n",
      "Number of clusters in train data (originally 100):  100\n"
     ]
    }
   ],
   "source": [
    "print train[\"hotel_cluster\"].value_counts()[:6]\n",
    "print  \"...\"\n",
    "print train[\"hotel_cluster\"].value_counts()[-5:]\n",
    "print \"Number of clusters in train data (originally 100): \", len(train.hotel_cluster.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which columns are present in train data, and absent in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In test set we don't have columns:  set(['hotel_cluster', 'cnt', 'is_booking'])\n"
     ]
    }
   ],
   "source": [
    "print \"In test set we don't have columns: \", set(train.columns) - set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all ids from test data present in train data\n",
    "test_ids = set(test.user_id.unique())\n",
    "train_ids = set(train.user_id.unique())\n",
    "intersection_count = len(test_ids & train_ids)\n",
    "intersection_count == len(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert the date_time column in train from an object to a datetime value. This makes it easier to work with as a date.\n",
    "* Extract the year and month from from date_time, and assign them to their own columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"date_time\"] = pd.to_datetime(train[\"date_time\"])\n",
    "train[\"year\"] = train[\"date_time\"].dt.year\n",
    "train[\"month\"] = train[\"date_time\"].dt.month\n",
    "\n",
    "test[\"date_time\"] = pd.to_datetime(test[\"date_time\"])\n",
    "test[\"year\"] = test[\"date_time\"].dt.year\n",
    "test[\"month\"] = test[\"date_time\"].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the original train and test DataFrames, test contained data from 2015, and train contained data from 2013 and 2014. We split this data so that anything after July 2014 is in t2, and anything before is in t1. This gives us smaller training and testing sets with similar characteristics to train and test.\n",
    "* If is_booking is 0, it represents a click, and a 1 represents a booking.  test contains only booking events, so we’ll need to sample t2 to only contain bookings as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = train[((train.year == 2013) | ((train.year == 2014) & (train.month < 8)))]\n",
    "t2 = train[((train.year == 2014) & (train.month >= 8))]\n",
    "t2 = t2[t2.is_booking == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1 \n",
    "\n",
    "The most simple technique we could try on this data is to find the most common clusters across the data, then use them as predictions.\n",
    "\n",
    "We can again use the value_counts method to help us here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91, 64, 48, 41, 5]\n"
     ]
    }
   ],
   "source": [
    "most_common_clusters = list(train.hotel_cluster.value_counts().head().index)\n",
    "print most_common_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will give us a list of the 5 most common clusters in train. This is because the head method returns the first 5 rows by default, and the index property will return the index of the DataFrame, which is the hotel cluster after running the value_counts method.\n",
    "\n",
    "### Generating predictions\n",
    "We can turn most_common_clusters into a list of predictions by making the same prediction for each row. This will create a list with as many elements as there are rows in t2. Each element will be equal to most_common_clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[91, 64, 48, 41, 5],\n",
       " [91, 64, 48, 41, 5],\n",
       " [91, 64, 48, 41, 5],\n",
       " [91, 64, 48, 41, 5],\n",
       " [91, 64, 48, 41, 5]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [most_common_clusters for i in range(t2.shape[0])]\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating error\n",
    "In order to evaluate error, we’ll first need to figure out how to compute Mean Average Precision. Luckily, Ben Hamner has written an implementation that can be found here. It can be installed as part of the ml_metrics package, and you can find installation instructions for how to install it here.\n",
    "\n",
    "We can compute our error metric with the mapk with this functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target needs to be in list of lists format for mapk to work, so we convert the hotel_cluster column of t2 into a list of lists. Then, we call the mapk method with our target, our predictions, and the number of predictions we want to evaluate (5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [32], [96], [72], [99]]\n",
      "[[91, 64, 48, 41, 5], [91, 64, 48, 41, 5], [91, 64, 48, 41, 5], [91, 64, 48, 41, 5], [91, 64, 48, 41, 5]]\n",
      "0.0664765456473\n"
     ]
    }
   ],
   "source": [
    "target = [[l] for l in t2[\"hotel_cluster\"]]\n",
    "print target[:5]\n",
    "print predictions[:5]\n",
    "print mapk(target, predictions, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result here isn’t great, but we’ve just generated our first set of predictions, and evaluated our error! The framework we’ve built will allow us to quickly test out a variety of techniques and see how they score. We’re well on our way to building a good-performing solution for the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2528243, 2)\n",
      "   id hotel_cluster\n",
      "0   0          99 1\n",
      "1   1          99 1\n",
      "2   2          99 1\n",
      "3   3          99 1\n",
      "4   4          99 1\n",
      "   id  hotel_cluster\n",
      "0   0  1 32 96 72 99\n",
      "1   1  1 32 96 72 99\n",
      "2   2  1 32 96 72 99\n",
      "3   3  1 32 96 72 99\n",
      "4   4  1 32 96 72 99\n"
     ]
    }
   ],
   "source": [
    "samp_sumb = pd.read_csv(\"sample_submission.csv\")\n",
    "print samp_sumb.shape\n",
    "print samp_sumb.head()\n",
    "\n",
    "x = '1 32 96 72 99'\n",
    "samp_sumb.hotel_cluster = ['1 32 96 72 99' for i in range(len(samp_sumb.hotel_cluster))]\n",
    "print samp_sumb.head()\n",
    "samp_sumb.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
